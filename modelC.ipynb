{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c7de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer \n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from category_encoders import TargetEncoder, BinaryEncoder\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import set_config\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import optuna\n",
    "from optuna.distributions import CategoricalDistribution, IntDistribution, FloatDistribution\n",
    "from optuna.integration import OptunaSearchCV, ShapleyImportanceEvaluator\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "plt.rc('font', family='malgun gothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b94e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv', encoding='cp949').drop(columns='ID')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').Salary\n",
    "\n",
    "X_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "test_id = X_test.ID\n",
    "X_test = X_test.drop(columns='ID')\n",
    "\n",
    "data = pd.concat([X_train, X_test]).reset_index().drop(columns='index')\n",
    "\n",
    "data.loc[data[data['직종']=='호텔/콘도/리조트'].index, '직종'] = '기타 직종'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5a2f6c9",
   "metadata": {},
   "source": [
    "# 피쳐 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d99b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대학성적 중앙값으로 처리\n",
    "imp = SimpleImputer(strategy='median')\n",
    "data['대학성적'] = imp.fit_transform(data['대학성적'].values.reshape(-1,1))\n",
    "\n",
    "# 자격증 보기 쉽게 변환\n",
    "data['자격증'] = data['자격증'].str.replace('無', 'x')\n",
    "data['자격증'] = data['자격증'].str.replace('有', 'o')\n",
    "\n",
    "# 근무 형태 처리\n",
    "null_list = data[data['근무경력']==0].index\n",
    "data['근무형태'][null_list] = data['근무형태'][null_list].fillna('경력없음')\n",
    "data['근무형태'] = data['근무형태'].fillna('missing')\n",
    "\n",
    "#\n",
    "data['근무형태'] = data['근무형태'].str.replace(',', ' ')\n",
    "data['근무형태'] = data['근무형태'].str.strip()\n",
    "data['근무형태'] = data.근무형태.str.replace(' ',',')\n",
    "\n",
    "\n",
    "\n",
    "# 어학 시험 전처리\n",
    "data['어학시험'] = data['어학시험'].fillna('없음')\n",
    "\n",
    "\n",
    "# 대학 전공 변환\n",
    "col_list = []\n",
    "abc = []\n",
    "for i in data.대학전공:\n",
    "    if '(' in i:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] == '(':\n",
    "                a = j\n",
    "            elif i[j] == ')':\n",
    "                b = j\n",
    "        last = i[b+1:]\n",
    "        first = i[:a]\n",
    "        i = first + last\n",
    "        abc.append(i)\n",
    "    col_list.append(i)    \n",
    "data['대학전공'] = col_list\n",
    "\n",
    "#\n",
    "data['대학전공'] = data['대학전공'].str.replace(',',' ')\n",
    "data['대학전공'] = data['대학전공'].str.replace('/', ' ')\n",
    "data['대학전공'] = data['대학전공'].str.replace('.',' ')\n",
    "data['대학전공'] = data['대학전공'].str.strip()\n",
    "data['대학전공'] = data['대학전공'].str.replace(' ','')\n",
    "\n",
    "#\n",
    "col = []\n",
    "for i in data['대학전공']:\n",
    "    if i[-1]=='과':\n",
    "        i = i[:-1]\n",
    "    col.append(i)    \n",
    "data['대학전공'] = col\n",
    "\n",
    "#\n",
    "col2 = []\n",
    "for i in data['대학전공']:\n",
    "    if i[-1]!='학':\n",
    "        i = i+'학'\n",
    "    col2.append(i)    \n",
    "data['대학전공'] = col2\n",
    "\n",
    "\n",
    "# 세부직종 처리\n",
    "def full(job):\n",
    "    value = data[data['세부직종']==job]['직무태그'].value_counts().index[0]\n",
    "    data.loc[data[data['세부직종']==job]['직무태그'].index, '직무태그'] = data[data['세부직종']==job]['직무태그'].fillna(value)\n",
    "    \n",
    "for i in data.세부직종.value_counts().index:\n",
    "    full(i)\n",
    "    \n",
    "# 어학시험 처리\n",
    "language1 = []\n",
    "for i in data['어학시험']:\n",
    "    if i == ' ':\n",
    "        i = '없음'\n",
    "    language1.append(i) \n",
    "data['어학시험'] = language1\n",
    "\n",
    "#\n",
    "language3 = []\n",
    "for i in data['어학시험']:\n",
    "    if i[:5] == 'TOEFL':\n",
    "        i = '토플'\n",
    "    language3.append(i) \n",
    "data['어학시험'] = language3\n",
    "\n",
    "#\n",
    "language4 = []\n",
    "for i in data['어학시험']:\n",
    "    if i in '기타':\n",
    "        i = '기타'\n",
    "    language4.append(i)\n",
    "data['어학시험'] = language4\n",
    "\n",
    "\n",
    "# 직무태그 처리  \n",
    "\n",
    "data['직무태그'] = data['직무태그'].str.replace(' ','')\n",
    "\n",
    "job_list = []\n",
    "for i in data['직무태그'].str.split(','):\n",
    "    job_list.append(sorted(i))    \n",
    "job_col = []\n",
    "\n",
    "for i in job_list:\n",
    "    result = ' '.join(map(str, i))\n",
    "    result = result.rstrip()\n",
    "    result = result.lstrip()\n",
    "    job_col.append(result)\n",
    "    \n",
    "data['직무태그'] = job_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3083b05b",
   "metadata": {},
   "source": [
    "# 대학전공 New 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a493f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['대학전공'] = data['대학전공'].str.replace('복수','')\n",
    "data['대학전공'] = data['대학전공'].str.replace('전공','')\n",
    "data['대학전공'] = data['대학전공'].str.replace('졸업','')\n",
    "data['대학전공'] = data['대학전공'].str.replace('중퇴','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cd3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in data['대학전공']:\n",
    "    if i[-1] == '학':\n",
    "        if i[-2:] == '공학':\n",
    "            pass\n",
    "        else:\n",
    "            i = i[:-1]\n",
    "        a.append(i)\n",
    "data['대학전공'] = a\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "a = []\n",
    "for i in data.대학전공:\n",
    "    a.append(okt.morphs(i))\n",
    "data['대학전공'] = a\n",
    "\n",
    "col = []\n",
    "for i in a:\n",
    "    result = ' '.join(map(str, i))\n",
    "    result = result.rstrip()\n",
    "    result = result.lstrip()\n",
    "    col.append(result)\n",
    "    \n",
    "data['대학전공'] = col\n",
    "\n",
    "data['대학전공'] = data['대학전공'].str.strip()\n",
    "data['대학전공'] = data['대학전공'].str.replace(' ',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ed09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별로 구분하여 Bow 방식 후 PCA\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = data['대학전공']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "features = vectorizer.fit_transform(sentences)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "new = pd.DataFrame(features.toarray(), columns = vocab)\n",
    "\n",
    "X_train_New = new[:16570]\n",
    "X_test_New = new[16570:]\n",
    "\n",
    "max_d = num_d = new.shape[1]\n",
    "pca = PCA(n_components=max_d).fit(X_train_New)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_d = np.argmax(cumsum >= 0.95) + 1\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0)  \n",
    "X_train_pca = pca.fit_transform(X_train_New)\n",
    "X_test_pca = pca.transform(X_test_New)\n",
    "\n",
    "train = pd.DataFrame(X_train_pca)\n",
    "test = pd.DataFrame(X_test_pca)\n",
    "\n",
    "all_pca = pd.concat([train, test]).reset_index().drop(columns = 'index')\n",
    "data = pd.concat([data, all_pca], axis=1).drop(columns='대학전공')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d75098f",
   "metadata": {},
   "source": [
    "# 근무경력 New 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f56fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 년 / 개월 구분하여 열 생성\n",
    "for i in range(len(data.근무경력)):\n",
    "    if len(data.근무경력[i]) == 3 or len(data.근무경력[i]) == 4:\n",
    "        data.근무경력[i] = '0년 ' + data.근무경력[i]\n",
    "\n",
    "we = data.근무경력.str.split(' ',expand=True)\n",
    "we.columns = ['년','개월']\n",
    "\n",
    "# year, month로 구분하여 열 생성\n",
    "we = data.근무경력.str.split(' ',expand=True)\n",
    "we.columns = ['년','개월']\n",
    "\n",
    "we_y = we.년.str.split('년', expand=True) \n",
    "we_y.columns = ['년','삭제']\n",
    "we_y.drop('삭제',axis=1,inplace=True)\n",
    "we_y = we_y.astype(int) \n",
    "\n",
    "we_m = we.개월.str.split('개월', expand=True)\n",
    "we_m.columns = ['개월','삭제']\n",
    "we_m.drop('삭제',axis=1,inplace=True)\n",
    "we_m = we_m.astype(int)\n",
    "\n",
    "data['근무경력_y'] = we_y['년']\n",
    "data['근무경력_m'] = we_m['개월']\n",
    "\n",
    "X_train = data.iloc[:X_train.shape[0],:].reset_index(drop=True)\n",
    "X_test = data.iloc[X_train.shape[0]:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f27ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in data['근무경력_y']:\n",
    "    if i==0: \n",
    "        b = '경력없음' \n",
    "    elif i <=2:\n",
    "        b = '하'\n",
    "    elif i <=4:\n",
    "        b = '중'\n",
    "    elif i <=6:\n",
    "        b = '중중'\n",
    "    else:\n",
    "        b = '상'\n",
    "    a.append(b)\n",
    "data['숙련도'] = a\n",
    "\n",
    "data.drop(columns='근무경력', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb2a29ab",
   "metadata": {},
   "source": [
    "# 직무태그 New 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d940d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['직무태그'] = data['직무태그'].str.strip()\n",
    "data['직무태그'] = data['직무태그'].str.replace(' ',',')\n",
    "\n",
    "a = []\n",
    "for i in data.직무태그.str.split(','):\n",
    "    b = len(i)\n",
    "    a.append(b)\n",
    "data['직무태그_갯수'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956f27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = data['직무태그']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "features = vectorizer.fit_transform(sentences)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "new = pd.DataFrame(features.toarray(), columns = vocab)\n",
    "\n",
    "X_train_New = new[:16570]\n",
    "X_test_New = new[16570:]\n",
    "\n",
    "max_d = num_d = new.shape[1]\n",
    "pca = PCA(n_components=max_d).fit(X_train_New)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_d = np.argmax(cumsum >= 0.8) + 1\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0)  \n",
    "X_train_pca = pca.fit_transform(X_train_New)\n",
    "X_test_pca = pca.transform(X_test_New)\n",
    "\n",
    "train = pd.DataFrame(X_train_pca)\n",
    "test = pd.DataFrame(X_test_pca)\n",
    "\n",
    "all_pca = pd.concat([train, test]).reset_index().drop(columns = 'index')\n",
    "data = pd.concat([data, all_pca], axis=1).drop(columns='직무태그')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e61c9497",
   "metadata": {},
   "source": [
    "# 근무지역 New 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a276232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in data.근무지역.str.split(','):\n",
    "    b = i[0]\n",
    "    a.append(b)\n",
    "data['첫희망지역'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca869068",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['근무지역'] = data['근무지역'].str.replace(',',' ')\n",
    "data['근무지역'] = data['근무지역'].str.strip()\n",
    "data['근무지역'] = data['근무지역'].str.replace(' ',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f099ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16570, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = data['근무지역']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "features = vectorizer.fit_transform(sentences)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "new = pd.DataFrame(features.toarray(), columns = vocab)\n",
    "\n",
    "X_train_New = new[:16570]\n",
    "X_test_New = new[16570:]\n",
    "\n",
    "max_d = num_d = new.shape[1]\n",
    "pca = PCA(n_components=max_d).fit(X_train_New)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_d = np.argmax(cumsum >= 0.9) + 1\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0)  \n",
    "X_train_pca = pca.fit_transform(X_train_New)\n",
    "X_test_pca = pca.transform(X_test_New)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "train = pd.DataFrame(X_train_pca)\n",
    "test = pd.DataFrame(X_test_pca)\n",
    "\n",
    "all_pca = pd.concat([train, test]).reset_index().drop(columns = 'index')\n",
    "data = pd.concat([data, all_pca], axis=1).drop(columns='근무지역')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9816fdbd",
   "metadata": {},
   "source": [
    "# 근무형태 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f83dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = data['근무형태']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "features = vectorizer.fit_transform(sentences)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "new = pd.DataFrame(features.toarray(), columns = vocab)\n",
    "\n",
    "X_train_New = new[:16570]\n",
    "X_test_New = new[16570:]\n",
    "\n",
    "max_d = num_d = new.shape[1]\n",
    "pca = PCA(n_components=max_d).fit(X_train_New)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_d = np.argmax(cumsum >= 0.95) + 1\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0)  \n",
    "X_train_pca = pca.fit_transform(X_train_New)\n",
    "X_test_pca = pca.transform(X_test_New)\n",
    "\n",
    "train = pd.DataFrame(X_train_pca)\n",
    "test = pd.DataFrame(X_test_pca)\n",
    "\n",
    "all_pca = pd.concat([train, test]).reset_index().drop(columns = 'index')\n",
    "data = pd.concat([data, all_pca], axis=1).drop(columns='근무형태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a7e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [i for i in range(data.columns.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd758f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:16570]\n",
    "X_test = data[16570:]\n",
    "\n",
    "X_test = X_test.reset_index()\n",
    "X_test.drop(columns='index', inplace=True)\n",
    "\n",
    "numeric_features = data.select_dtypes('number').columns.to_list()\n",
    "categorical_features = data.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf7eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 스태킹시 활용하기 위해 파일 저장\n",
    "\n",
    "# X_train.to_csv('X_train1.csv', encoding='cp949')\n",
    "# X_test.to_csv('X_test1.csv', encoding='cp949')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a67b9f47",
   "metadata": {},
   "source": [
    "# K-Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc17ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [830.36470025 816.26249952 830.26305555 798.15747085 806.10600119]\n",
      "CV mean = 816.23 with std = 12.85\n"
     ]
    }
   ],
   "source": [
    "scores = []  # CV 결과 저장\n",
    "oof_pred = np.zeros(X_test.shape[0])  # OOF 저장\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, valid_index in kfold.split(X_train, y_train): \n",
    "    # 학습/검증 데이터 분할\n",
    "    train_x, valid_x = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    train_y, valid_y = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "    # 범주형피처 직접 처리와 Early stopping을 사용하여 CatBoost 모델링\n",
    "    model = CatBoostRegressor(cat_features=categorical_features, verbose=False, random_state=0)\n",
    "    model.fit(train_x, train_y,\n",
    "              eval_set=[(valid_x,valid_y)],\n",
    "              early_stopping_rounds=100,\n",
    "             )\n",
    "\n",
    "    # CV 스코어 계산 및 저장\n",
    "    rmse = np.sqrt(mean_squared_error(valid_y, model.predict(valid_x)))\n",
    "    scores.append(rmse)\n",
    "\n",
    "    # OOF 예측값 저장\n",
    "    oof_pred += model.predict(X_test) / kfold.get_n_splits()\n",
    "    \n",
    "scores = np.array(scores)\n",
    "print(\"CV scores: \", scores)\n",
    "print(\"CV mean = %.2f\" % scores.mean(), \"with std = %.2f\" % scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5263b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'[3]catboost_modelC_{scores.mean():.2f}_{scores.std():.2f}.csv'\n",
    "pd.DataFrame({'ID':test_id, 'Salary':oof_pred}).to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
